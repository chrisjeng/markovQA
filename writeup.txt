Introduction:

Our project is Relationship Guru. Tell the bot about any relationship problems/questions you may have, and it will immediately scrape relevant Reddit posts to educate itself, and give you a sophisticated answer to your problems! We essentially have a Markov chain, weighted by relevance and upvotes (the more relevant the post is, and the more upvotes it has, the more important the data is). In addition to giving relationship advice, the bot has additional features like Obama speech generation (make Obama), Trump twitter generation (-t flag), and also non-serious mode (weight down-voted answers more heavily). 

Methods:

The heart of the sentence generation is the Markov chain. When given sample answer data, each pair of words is parsed and connected in an internal Markov chain. Each file is given a fixed weight, so that all pairings of words from the file have that weighting. Weightings are cumulative, and normalized after all file processing has occurred (and we are generating sentences). 

Sentence generation occurs by starting on a (uniform) randomly chosen word, and a random walk as weighted by the internal data. When aiming for a target length (such as 100 words), after a certain threshold, we attempt to end on the next word that is naturally paired with punctuation. If after an additional 50% length we still have not yet come across a naturally punctuated word, we force the ending and append a period. Strings are built using the java StringBuilder to boost runtime (but in terms of runtime, the limiting factor is easily the Reddit scraping cap, and not our actual code).

Experiments:

Reddit limits our scraping to a declared 1 request every 2 seconds, but is realistically more along the lines of 1 request every 8 seconds. We had to morph the Python scraping to be more acceptable, to avoid the dreaded "Too many requests" error. 

Results/Analysis:
Discussion/Limitations:
Initially, we wanted to scrape Quora and apply PageRank on the user-upvote network to get a reasonable weight for our data. For example, users with many followers and highly upvoted answers would receive high weight scores, and recursively, if those followers are themselves important, the weighting score goes up even more. However, Quora is difficult to scrape with our Python BeautifulSoup code because Quora requires authentication to view the posts (boo!). We instead decided to scrape Reddit, because the html of the site wasn't too difficult to parse, and the data would be more comical in nature. 

Another major feature we didn't explore was NLP. Currently, our Markov chain runs blindly off of the data, and there is no grammatical thinking or sentence structure correction. Punctuation can also be unnatural. Our answers would make more sense if we applied NLP to the output, but we never explored doing so because that's beyond the scope of a short project. 